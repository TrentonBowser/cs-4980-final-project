---
title: "Chicago Crime Prediction"
output:
  html_document:
    df_print: paged
---

## Package Importing 
In this project, we will be utilizing the `tidyverse` and `lubridate` packages for data management and data handling.

```{r message=FALSE}
library(tidyverse)
library(lubridate)
library(randomForest)
library(caret)
require(caTools)
```

## Hypotheses

1) The likelihood of an arrest can be calculated from the type of crime and weather features

2) The likelihood of an arrest can be calculated from the type of crime and the crime's location in relation of libraries, parks, and public art

3) Days with inclement weather will have different amounts of the most common crime (Battery and Theft) than days without inclement weather


## Datasets
We have decided to use multiple different datasets for this project, allowing us to pull broader and more impactful relations within our data. Each of the datasets we are using will be imported below, with an explanation and information on each.

### Chicago Crime Dataset
The Chicago Crime dataset contains records of most crimes that the Chicago Police responded to, between the years of 2001 to present, and has been aggregated by the City of Chicago. 

The dataset contains nearly 7,500,000 entries, with 22 total features. Features include information about the date and location of the crime, as well as information about the type of crime and description of events. During this experiment, we will primarily be using the `Primary Type` feature (listing the type of crime) as a target variable, in order to determine if there are external factors to the types of crimes being predicted. As a note, we have only selected a more recent subset of the data, to focus on the current state of crime in the city, and to make the data more workable.

This dataset can be sourced from the [City of Chicago website](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2).
```{r eval=FALSE}
crime_data <- read_csv(
  "data/chicago-crime-dataset.csv",
  col_names = TRUE,
  locale = locale("en", tz="US/Central"),
  na = c("", "NA"),
  skip_empty_rows = TRUE,
  show_col_types = FALSE,
)
```

### NOAA Chicago Weather Dataset
The NOAA Chicago Weather dataset contains over 25,000 entries, corresponding to daily weather information from the Chicago area for roughly the last 65 years, all recorded by a Chicago weather station and aggregated by the National Oceanic and Atmospheric Administration (NOAA).

This dataset contains information about the location of the weather station taking the data, information about average temperature, wind speeds, precipitation, snow, and other inclement weather. We will be using this dataset to determine whether or not certain weather events have an impact on the types of crimes being committed, and if more severe crimes are more likely during certain weather events.

This dataset can be sourced from the [NOAA website](https://www.weather.gov/wrh/Climate?wfo=lot).

```{r eval=FALSE}
weather_data <- read_csv(
  "data/noaa-chicago-weather.csv",
  col_names = TRUE,
  locale = locale("en", tz="US/Central"),
  na = c("", "NA"),
  skip_empty_rows = TRUE,
  show_col_types = FALSE,
)
```


### Chicago Park Dataset
The Chicago Park dataset contains over 4300 entries, corresponding to different facilities and locations of public parks in the Greater Chicago area. All entries were recorded and distributed by the City of Chicago.

This dataset contains locations and boundaries of the public parks within the Chicago area, along with the facilities located inside of the parks (such as tennis courts, pools, soccer fields, etc). In addition to this, the dataset contains information about the park ID internal to the City of Chicago's records, as well as the park name. We will be using this dataset to determine whether or not certain parks are correlated to the severity and/or rate of crimes in their area.

This dataset can be sourced from the [City of Chicago website](https://data.cityofchicago.org/Parks-Recreation/Parks-Chicago-Park-District-Facilities-current-/5yyk-qt9y).

```{r eval=FALSE}
park_data <- read_csv(
  "data/chicago-parks-data.csv",
  col_names = TRUE,
  locale = locale("en", tz="US/Central"),
  na = c("", "NA"),
  skip_empty_rows = TRUE,
  show_col_types = FALSE,
)
```

### Chicago Library Dataset
The Chicago Library dataset contains over 80 entries of libraries in the Chicago area. It has been aggregated and distributed by the City of Chicago.

This dataset contains location data (latitude, longitude, and address) for libraries in the Chicago area, as well as the library name, hours of operation, and contact information. We will be using this dataset to determine whether or not certain libraries are correlated to the severity and/or rates of crimes in their area.

This dataset can be sourced from the [City of Chicago website](https://data.cityofchicago.org/Education/Libraries-Locations-Hours-and-Contact-Information-/wa2i-tm5d).

```{r eval=FALSE}
library_data <- read_csv(
  "data/chicago-libraries-data.csv",
  col_names = TRUE,
  locale = locale("en", tz="US/Central"),
  na = c("", "NA"),
  skip_empty_rows = TRUE,
  show_col_types = FALSE,
)
```

### Chicago Public Art Dataset
The Chicago Public Art dataset contains nearly 200 entries of public art locations in Chicago parks. This dataset has been aggregated and distributed by the City of Chicago.

This dataset contains information about the parks containing the artwork, the type of art, the artist, the owner, and latitude/longitude location of the art piece. We will be using it to determine if there is any difference in the types of crimes, or if more severe crimes are committed more/less often within close proximity to public art establishments.

This dataset can be sourced from the [City of Chicago website](https://data.cityofchicago.org/Parks-Recreation/Parks-Public-Art/sj6t-9cju/data).

```{r eval=FALSE}
art_data <- read_csv(
  "data/chicago-public-art-data.csv",
  col_names = TRUE,
  locale = locale("en", tz="US/Central"),
  na = c("", "NA"),
  skip_empty_rows = TRUE,
  show_col_types = FALSE,
)
```




## Data Preprocessing
In this section, we pre-process the data before testing and modelling on it. This includes removing un-needed columns in the data, as well as combining the data into a single, usable source.

### Data Cleaning
```{r eval=FALSE}
cleaned_crime_data <- select(crime_data, -c(ID,'Case Number' , Block, 'X Coordinate', 'Y Coordinate', Year, 'Updated On', Location))
cleaned_crime_data$DateTime <- mdy_hms(cleaned_crime_data$Date)
cleaned_crime_data$Date <- date(cleaned_crime_data$DateTime)
cleaned_crime_data <- cleaned_crime_data %>%
  drop_na() %>%
  filter(Date > "2020-01-01")

cleaned_crime_data$Latitude <- as.numeric((cleaned_crime_data$Latitude))
cleaned_crime_data$Longitude <- as.numeric((cleaned_crime_data$Longitude))

cleaned_crime_data$IUCR <- as.factor(cleaned_crime_data$IUCR)
cleaned_crime_data$`Primary Type` <- as.factor(cleaned_crime_data$`Primary Type`)
cleaned_crime_data$Description <- as.factor(cleaned_crime_data$Description)
cleaned_crime_data$`Location Description` <- as.factor(cleaned_crime_data$`Location Description`)
cleaned_crime_data$`FBI Code` <- as.factor(cleaned_crime_data$`FBI Code`)
```

```{r eval=FALSE}
cleaned_weather_data <- select(weather_data, -c(STATION, NAME, LATITUDE, LONGITUDE, ELEVATION))
cleaned_weather_data$DATE <- mdy(cleaned_weather_data$DATE)
cleaned_weather_data <- cleaned_weather_data %>%
  rename(Date=DATE,
         Fog=WT01,
         Heavy_Fog=WT02,
         Thunder=WT03,
         Ice_Rain=WT04,
         Hail=WT05,
         Glaze=WT06,
         Dust=WT07,
         Smoke=WT08,
         Blowing_Snow=WT09,
         Tornado=WT10,
         High_Winds=WT11,
         Mist=WT13,
         Drizzle=WT14,
         Freezing_Drizzle=WT15,
         Rain=WT16,
         Freezing_Rain=WT17,
         Snow_Precip=WT18,
         Unknown_Precip=WT19,
         Ground_Fog=WT21,
         Ice_Fog=WT22,
         Thunder_2=WV03,
         Rain_Snow_Shower=WV20)

cleaned_weather_data <- cleaned_weather_data %>%
  mutate(Fog=ifelse(is.na(Fog), 0, Fog),
         Heavy_Fog=ifelse(is.na(Heavy_Fog), 0, Heavy_Fog),
         Thunder=ifelse(is.na(Thunder), 0, Thunder),
         Ice_Rain=ifelse(is.na(Ice_Rain), 0, Ice_Rain),
         Hail=ifelse(is.na(Hail), 0, Hail),
         Glaze=ifelse(is.na(Glaze), 0, Glaze),
         Dust=ifelse(is.na(Dust), 0, Dust),
         Smoke=ifelse(is.na(Smoke), 0, Smoke),
         Blowing_Snow=ifelse(is.na(Blowing_Snow), 0, Blowing_Snow),
         Tornado=ifelse(is.na(Tornado), 0, Tornado),
         High_Winds=ifelse(is.na(High_Winds), 0, High_Winds),
         Mist=ifelse(is.na(Mist), 0, Mist),
         Drizzle=ifelse(is.na(Drizzle), 0, Drizzle),
         Freezing_Drizzle=ifelse(is.na(Freezing_Drizzle), 0, Freezing_Drizzle),
         Rain=ifelse(is.na(Rain), 0, Rain),
         Freezing_Rain=ifelse(is.na(Freezing_Rain), 0, Freezing_Rain),
         Snow_Precip=ifelse(is.na(Snow_Precip), 0, Snow_Precip),
         Unknown_Precip=ifelse(is.na(Unknown_Precip), 0, Unknown_Precip),
         Ground_Fog=ifelse(is.na(Ground_Fog), 0, Ground_Fog),
         Ice_Fog=ifelse(is.na(Ice_Fog), 0, Ice_Fog),
         Thunder_2=ifelse(is.na(Thunder_2), 0, Thunder_2),
         Rain_Snow_Shower=ifelse(is.na(Rain_Snow_Shower), 0, Rain_Snow_Shower))

cleaned_weather_data$Fog <- as.logical(cleaned_weather_data$Fog)
cleaned_weather_data$Heavy_Fog <- as.logical(cleaned_weather_data$Heavy_Fog)
cleaned_weather_data$Thunder <- as.logical(cleaned_weather_data$Thunder)
cleaned_weather_data$Ice_Rain <- as.logical(cleaned_weather_data$Ice_Rain)
cleaned_weather_data$Hail <- as.logical(cleaned_weather_data$Hail)
cleaned_weather_data$Glaze <- as.logical(cleaned_weather_data$Glaze)
cleaned_weather_data$Dust <- as.logical(cleaned_weather_data$Dust)
cleaned_weather_data$Smoke <- as.logical(cleaned_weather_data$Smoke)
cleaned_weather_data$Blowing_Snow <- as.logical(cleaned_weather_data$Blowing_Snow)
cleaned_weather_data$Tornado <- as.logical(cleaned_weather_data$Tornado)
cleaned_weather_data$High_Winds <- as.logical(cleaned_weather_data$High_Winds)
cleaned_weather_data$Mist <- as.logical(cleaned_weather_data$Mist)
cleaned_weather_data$Drizzle <- as.logical(cleaned_weather_data$Drizzle)
cleaned_weather_data$Freezing_Drizzle <- as.logical(cleaned_weather_data$Freezing_Drizzle)
cleaned_weather_data$Rain <- as.logical(cleaned_weather_data$Rain)
cleaned_weather_data$Freezing_Rain <- as.logical(cleaned_weather_data$Freezing_Rain)
cleaned_weather_data$Snow_Precip <- as.logical(cleaned_weather_data$Snow_Precip)
cleaned_weather_data$Unknown_Precip <- as.logical(cleaned_weather_data$Unknown_Precip)
cleaned_weather_data$Ground_Fog <- as.logical(cleaned_weather_data$Ground_Fog)
cleaned_weather_data$Ice_Fog <- as.logical(cleaned_weather_data$Ice_Fog)
cleaned_weather_data$Thunder_2 <- as.logical(cleaned_weather_data$Thunder_2)
cleaned_weather_data$Rain_Snow_Shower <- as.logical(cleaned_weather_data$Rain_Snow_Shower)
```


```{r eval=FALSE}
cleaned_park_data <- select(park_data, -c(OBJECTID, the_geom, GISOBJID))
cleaned_park_data <- rename(cleaned_park_data, Longitude = X_COORD, Latitude = Y_COORD)

cleaned_park_data$Latitude <- as.numeric(cleaned_park_data$Latitude)
cleaned_park_data$Longitude <- as.numeric(cleaned_park_data$Longitude)

cleaned_park_data$PARK_NO <- as.factor(cleaned_park_data$PARK_NO)
cleaned_park_data$PARK <- as.factor(cleaned_park_data$PARK)
cleaned_park_data$FACILITY_N <- as.factor(cleaned_park_data$FACILITY_N)
cleaned_park_data$FACILITY_T <- as.factor(cleaned_park_data$FACILITY_T)
```

```{r eval=FALSE}
cleaned_library_data <- select(library_data, -c("HOURS OF OPERATION", ADDRESS, CITY, STATE, ZIP, PHONE, WEBSITE))
cleaned_library_data$LOCATION <- str_remove_all(cleaned_library_data$LOCATION, "[ \\(\\)]")
cleaned_library_data <- cleaned_library_data %>% separate(LOCATION, c("Latitude", "Longitude"), ",")

cleaned_library_data$Latitude <- as.numeric(cleaned_library_data$Latitude)
cleaned_library_data$Longitude <- as.numeric(cleaned_library_data$Longitude)
```

```{r eval=FALSE}
cleaned_art_data <- select(art_data, -c("X COORDINATE", "Y COORDINATE", LOCATION, OWNER))
cleaned_art_data <- rename(cleaned_art_data, Longitude = LONGITUDE, Latitude = LATITUDE)

cleaned_art_data$Latitude <- as.numeric(cleaned_art_data$Latitude)
cleaned_art_data$Longitude <- as.numeric(cleaned_art_data$Longitude)

cleaned_art_data$`PARK NAME` <- as.factor(cleaned_art_data$`PARK NAME`)
cleaned_art_data$`PARK NUMBER` <- as.factor(cleaned_art_data$`PARK NUMBER`)
cleaned_art_data$ARTIST <- as.factor(cleaned_art_data$ARTIST)
```

### Combining Data

```{r eval=FALSE}
combined_data <- cleaned_crime_data %>% left_join(cleaned_weather_data, by="Date")
combined_data <- select(combined_data, -Date)

# Cleaning up previous data sets in environment
rm(art_data)
rm(crime_data)
rm(library_data)
rm(park_data)
rm(weather_data)
```



#### Adding Nearest Park To Crime
```{r eval=FALSE}

park_locations <-cleaned_park_data %>%
  group_by(PARK_NO) %>%
  summarize_at(vars(Longitude:Latitude), mean)

# Function to calculate the distance between two latitude and longitude values (Haversine Formula)
calculate_distance <- function(row, lat1, long1){
  radius <- 3958.8
  d_lat <- abs(lat1-as.numeric(row["Latitude"])) * pi / 180.0
  d_long <- abs(long1-as.numeric(row["Longitude"])) * pi / 180.0
  
  temp1 <- (sin(d_lat/2.0)**2) +
    ((cos(lat1*pi/180.0) * cos(as.numeric(row["Latitude"])*pi/180.0)) *
    (sin(d_long/2.0)**2))
  temp2 <- 2 * atan2(sqrt(temp1), sqrt(1.0-temp1))
  return(temp2*radius)
}

# Function that finds the closest park and its distance from each crime row
get_closest_park_function <- function(row){
  park_distances <- apply(park_locations, MARGIN=1, FUN=calculate_distance, lat1=as.numeric(row["Latitude"]), long1=as.numeric(row["Longitude"]))
  closest_park_index <- which.min(park_distances)
  
  closest_dist <- park_distances[closest_park_index]
  closest_park <- (park_locations %>% slice(closest_park_index))$PARK_NO
  
  return(c(closest_park, closest_dist))
}


closest_parks <- apply(combined_data, MARGIN=1, FUN=get_closest_park_function)
combined_data <- combined_data %>% add_column(closest_park = closest_parks[1,], park_dist = closest_parks[2,])
```

#### Adding Nearest Library To Crime
```{r eval=FALSE}
# Function that finds the closest library and its distance from each crime row
get_closest_library_function <- function(row){
  library_distances <- apply(cleaned_library_data, MARGIN=1, FUN=calculate_distance, lat1=as.numeric(row["Latitude"]), long1=as.numeric(row["Longitude"]))
  closest_library_index <- which.min(library_distances)
  
  closest_dist <- library_distances[closest_library_index]
  closest_library <- (cleaned_library_data %>% slice(closest_library_index))$NAME
  
  return(c(closest_library, closest_dist))
}

closest_libraries <- apply(combined_data, MARGIN=1, FUN=get_closest_library_function)
combined_data <- combined_data %>% add_column(closest_library = closest_libraries[1,], library_dist = closest_libraries[2,])
```

#### Adding Nearest Art To Crime
```{r eval=FALSE}
# Function that finds the closest art and its distance from each crime row
get_closest_art_function <- function(row){
  art_distances <- apply(cleaned_art_data, MARGIN=1, FUN=calculate_distance, lat1=as.numeric(row["Latitude"]), long1=as.numeric(row["Longitude"]))
  closest_art_index <- which.min(art_distances)
  
  closest_dist <- art_distances[closest_art_index]
  closest_art <- (cleaned_art_data %>% slice(closest_art_index))$`ART`
  
  return(c(closest_art, closest_dist))
}

closest_artwork <- apply(combined_data, MARGIN=1, FUN=get_closest_art_function)
combined_data <- combined_data %>% add_column(closest_art = closest_artwork[1,], art_dist = closest_artwork[2,])
rm(closest_artwork)
```


```{r eval=FALSE}
combined_data$closest_park <- as.factor(combined_data$closest_park)
combined_data$closest_library <- as.factor(combined_data$closest_library)
combined_data$closest_art <- as.factor(combined_data$closest_art)

combined_data$park_dist <- as.double(combined_data$park_dist)
combined_data$library_dist <- as.double(combined_data$library_dist)
combined_data$art_dist <- as.double(combined_data$art_dist)
```

```{r echo=FALSE}
load("all-data-combined.RData")
```

## Data Analysis and Visualization
In this section, we look at the different datasets that are being imported, and create basic visualizations to determine what the makeup and distribution of the data is. 


### Chicago Crime Dataset

There are a total of `r length(unique(cleaned_crime_data$IUCR))` unique crimes

```{r}
ggplot(cleaned_park_data, aes(x=Longitude, y=Latitude)) +
  ggtitle("Location of Parks") +
  geom_point()
```

```{r}
cleaned_crime_data %>%
  mutate(fac_type=`Primary Type` %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=20)) %>%
  ggplot(aes(x=fac_type)) +
  ggtitle("Instances of Chicago Crimes") +
  xlab("Primary Crime Type") + 
  ylab("Count") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_bar()
```


### NOAA Chicago Weather Dataset

There are a total of `r length(colnames(cleaned_park_data))` unique features in the dataset.

### Chicago Park Dataset

There are a total of `r length(unique(cleaned_park_data$PARK))` unique parks in the dataset.

There are a total of `r length(unique(cleaned_park_data$FACILITY_N))` unique facility types in the dataset.

There are a total of `r length(unique(cleaned_park_data$FACILITY_T))` unique facility locations in the dataset.

```{r}
ggplot(cleaned_park_data, aes(x=Longitude, y=Latitude)) +
  ggtitle("Location of Parks") +
  geom_point()
```

```{r}
cleaned_park_data %>%
  mutate(fac_type=FACILITY_N %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=20)) %>%
  ggplot(aes(x=fac_type)) +
  ggtitle("Count of Facility Types") +
  xlab("Facility Type") + 
  ylab("Count") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_bar()
```


```{r}
cleaned_park_data %>%
  mutate(fac_type=FACILITY_T %>% fct_infreq()) %>%
  ggplot(aes(x=fac_type)) +
  ggtitle("Count of Facility Locations") +
  xlab("Facility Location") + 
  ylab("Count") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_bar()
```

### Chicago Library Dataset

There are a total of `r length(unique(cleaned_library_data$NAME))` unique libraries in the dataset.

```{r}
ggplot(cleaned_library_data, aes(x=Longitude, y=Latitude)) +
  ggtitle("Location of Libraries") +
  geom_point()
```


### Chicago Public Art Dataset

There are a total of `r length(unique(cleaned_art_data$ART))` unique pieces of art in the dataset.

```{r}
scale <- function(x) sprintf("%.1f", x)

ggplot(cleaned_art_data, aes(x=Longitude, y=Latitude)) +
  ggtitle("Location of Artwork") +
  geom_point()
```


### Hypothesis 1 Testing
Hypothesis: The likelihood of an arrest can be calculated from the type of crime and weather features.


#### Visualization
We wanted to visualize some of the relationships between our variables of interest. Here we have the amount of precipitation that day (in inches) mapped with whether or not they resulted in an arrest.
```{r}
ggplot(combined_data, aes(x=Arrest, y= PRCP)) +
  xlab("Arrest") + 
  ylab("Precipitation That Day (in)") +
  geom_boxplot() +
  coord_cartesian(ylim =  c(0, 0.5))
```

Then we looked for any relationship between arrests and the amount of snow Chicago got that day (in inches). 
```{r}
ggplot(combined_data, aes(x=Arrest, y= SNOW)) + 
  xlab("Arrest") + 
  ylab("Amount of Snow That Day (in)") +
  geom_boxplot()
```

Then we looked for any relationship between arrests and the average temperature for the day.
```{r}
ggplot(combined_data, aes(x=Arrest, y= TAVG)) + 
  xlab("Arrest") + 
  ylab("Average Temperature for the Day (F)") +
  geom_boxplot()
```

Then we looked for any relationship between arrests and the highest temperature of the day.
```{r}
ggplot(combined_data, aes(x=Arrest, y= TMAX)) + 
  xlab("Arrest") + 
  ylab("Highest Temperature of the Day (F)") +
  geom_boxplot()
```

Then we looked for any relationship between arrests and the lowest temperature of the day. 
```{r}
ggplot(combined_data, aes(x=Arrest, y= TMIN)) + 
  xlab("Arrest") + 
  ylab("Lowest Temperature of the Day (F)") +
  geom_boxplot()
```

Then we looked for any relationship between the type of crime and the amount of precipitation. 
```{r}
combined_data %>% mutate(fac_type=`Primary Type` %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=10)) %>%
  ggplot(aes(x=fac_type, y= PRCP)) +
  ggtitle("Chicago Precipitation and Crime Types") +
  xlab("Primary Crime Type") + 
  ylab("Amount of Precipitation") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_boxplot() +
  coord_cartesian(ylim =  c(0, 0.15))
```

Then we looked for any relationship between the type of crime and the average temperature for the day. 
```{r}
combined_data %>% mutate(fac_type=`Primary Type` %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=10)) %>%
  ggplot(aes(x=fac_type, y= TAVG)) +
  ggtitle("Chicago Temperature and Crime Types") +
  xlab("Primary Crime Type") + 
  ylab("Average Temperature") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_boxplot()
```

We also looked at the relationship between type of crime and whether it resulted in an arrest.
```{r}
combined_data %>% mutate(fac_type=`Primary Type` %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=10)) %>%
  ggplot(aes(fac_type, ..count..)) +
  ggtitle("Chicago Crime Types vs Arrests") +
  xlab("Primary Crime Type") + 
  ylab("Number of Crimes") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_bar(aes(fill=Arrest))
```

And calculated the ratio of arrests to each specific crime.
```{r}
combined_data %>% 
  count(`Primary Type`, Arrest, .drop=FALSE) %>%
  complete(`Primary Type`, Arrest) %>%
  group_by(`Primary Type`) %>%
  mutate(percent_arrested = n[Arrest == TRUE]/sum(n)) %>%
  filter(Arrest == FALSE) %>%
  select(-c(Arrest, n)) %>%
  arrange(desc(percent_arrested))
```



#### Statistical Testing
We then did some statistical testing to see whether the variables we will use in our model are statistically significant to an arrest occurring using an alpha of 0.05.
```{r}
wilcox.test(PRCP~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(SNOW~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(TAVG~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(TMAX~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(TMIN~ Arrest,
            data = combined_data,
            exact = FALSE)

chisq.test(with(combined_data,table(Arrest, `Primary Type`)))
```

#### Modeling and Prediction
Then we created a logistic regression model to predict arrests given just the primary type of crime.
```{r}
# Split data into training and testing datasets
set.seed(123)
training.samples <- sample(seq_len(nrow(combined_data)), size = floor(0.8 * nrow(combined_data)))
train.data  <- combined_data[training.samples, ]
test.data <- combined_data[-training.samples, ]
rm(training.samples)

# Fitting logistic regression model to predict arrests with just primary type
model <- glm(Arrest ~ `Primary Type`, data = train.data, family = binomial)

# Make predictions
probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "TRUE", "FALSE")
# Model accuracy
cat('Logistic Regression Model Accuracy w/ just primary type: ', round(mean(predicted.classes == test.data$Arrest, na.rm=TRUE),4) * 100, '%')
```

Then we created an additional logistic regression model to predict arrests given the amount of precipitation and type of crime.
```{r}
# Fitting logistic regression model to predict arrests with primary type of crime and precipitation amount
model <- glm(Arrest ~ `Primary Type` + PRCP, data = train.data, family = binomial)

# Make predictions
probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "TRUE", "FALSE")
# Model accuracy
cat('Logistic Regression Model Accuracy w/ added precipitation amount: ', round(mean(predicted.classes == test.data$Arrest, na.rm=TRUE),4) * 100, '%')
```


We then created a third logistic regression model to predict arrests given the type of crime and the average, highest, and lowest temperatures for the day.
```{r}
# Fitting logistic regression model to predict arrests with primary type and average, max, and min temperature
model <- glm(Arrest ~ `Primary Type` + TAVG + TMAX + TMIN, data = train.data, family = binomial)

# Make predictions
probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "TRUE", "FALSE")
# Model accuracy
cat('Logistic Regression Model Accuracy w/ added temperature info: ', round(mean(predicted.classes == test.data$Arrest, na.rm=TRUE),4) * 100, '%')
```

Summary output of the best performing model.
```{r}
# Summarize the best model
summary(model)
```

#### Results
The type of crime was the only statistically significant feature when trying to predict the likelihood of an arrest. The precipitation, snow, and temperature information was also statistically significant, but the significance was not enough to contribute to the predictions of a model. Because of this, we had to reject our alternative hypothesis that weather information can be used to predict the likelihood of an arrest for a crime. We suspect this is because the conditions of the day's weather should not and did not determine whether someone was arrested for a crime.


### Hypothesis 2 Testing
Hypothesis: The likelihood of an arrest can be calculated from the type of crime and the crime's location in relation of libraries, parks, and public art.


#### Visualization
We wanted to visualize some of the relationships between our variables of interest. Here we have the locations of the crimes mapped with whether or not they resulted in an arrest.
```{r}
ggplot(combined_data, aes(x=Longitude, y=Latitude, col=Arrest)) +
  ggtitle("Location of Crime") +
  geom_point()
```

Here we are looking for any relationship between arrests and the distance to art.
```{r}
ggplot(combined_data, aes(x=Arrest, y= art_dist)) + 
  xlab("Arrest") + 
  ylab("Distance to Art") +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim =  c(0, 3))
```

Here we are reviewed the relationship between arrests and the distance to the parks.
```{r}
ggplot(combined_data, aes(x=Arrest, y= park_dist)) + 
  xlab("Arrest") + 
  ylab("Distance to Park") +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim =  c(0, 0.75))
```

Then we looked for any difference between the type of crime and the distance to the public art. 
```{r}
combined_data %>% mutate(fac_type=`Primary Type` %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=10)) %>%
  ggplot(aes(x=fac_type, y= art_dist)) +
  ggtitle("Art Distances from Chicago Crime Types") +
  xlab("Primary Crime Type") + 
  ylab("Distance to Public Art") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim =  c(0, 3.25))
```

Then we looked for any difference between the type of crime and the distance to the parks. 
```{r}
combined_data %>% mutate(fac_type=`Primary Type` %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=10)) %>%
  ggplot(aes(x=fac_type, y= park_dist)) +
  ggtitle("Art Distances from Chicago Crime Types") +
  xlab("Primary Crime Type") + 
  ylab("Distance to Closest Park") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim =  c(0, 1))
```

We also looked at the relationship between type of crime and whether it resulted in an arrest.
```{r}
combined_data %>% mutate(fac_type=`Primary Type` %>% fct_infreq()) %>%
  mutate(fac_type=fct_lump(fac_type, n=10)) %>%
  ggplot(aes(fac_type, ..count..)) +
  ggtitle("Chicago Crime Types vs Arrests") +
  xlab("Primary Crime Type") + 
  ylab("Number of Crimes") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  geom_bar(aes(fill=Arrest))
```

And calculated the ratio of arrests to each specific crime.
```{r}
combined_data %>% 
  count(`Primary Type`, Arrest, .drop=FALSE) %>%
  complete(`Primary Type`, Arrest) %>%
  group_by(`Primary Type`) %>%
  mutate(percent_arrested = n[Arrest == TRUE]/sum(n)) %>%
  filter(Arrest == FALSE) %>%
  select(-c(Arrest, n)) %>%
  arrange(desc(percent_arrested))
```



#### Statistical Testing
We then did some statistical testing to see whether the variables we will use in our model are statistically significant to an arrest occurring using an alpha of 0.05.
```{r}
wilcox.test(Latitude~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(Longitude~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(park_dist~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(library_dist~ Arrest,
            data = combined_data,
            exact = FALSE)
wilcox.test(art_dist~ Arrest,
            data = combined_data,
            exact = FALSE)

chisq.test(with(combined_data,table(Arrest, `Primary Type`)))
```

#### Modeling and Prediction
Then we created a logistic regression model to predict arrests given the crime location.
```{r}
# Split data into training and testing datasets
set.seed(123)
training.samples <- sample(seq_len(nrow(combined_data)), size = floor(0.8 * nrow(combined_data)))
train.data  <- combined_data[training.samples, ]
test.data <- combined_data[-training.samples, ]
rm(training.samples)

# Fitting logistic regression model to predict arrests with just location
model <- glm( Arrest ~ Latitude + Longitude , data = train.data, family = binomial)

# Make predictions
probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "TRUE", "FALSE")
# Model accuracy
cat('Logistic Regression Model Accuracy w/ just crime location: ', round(mean(predicted.classes == test.data$Arrest),4) * 100, '%')
```

Then we created an additional logistic regression model to predict arrests given the location and type of crime.
```{r}
# Fitting logistic regression model to predict arrests with location and type of crime
model <- glm( Arrest ~ `Primary Type` + Latitude + Longitude, data = train.data, family = binomial)

# Make predictions
probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "TRUE", "FALSE")
# Model accuracy
cat('Logistic Regression Model Accuracy w/o added distances: ', round(mean(predicted.classes == test.data$Arrest),4) * 100, '%')
```


We then created a third logistic regression model to predict arrests given the type of crime and the distances to the nearest library, park, and public art.
```{r}
# Fitting logistic regression model to predict arrests without using distances to parks, art, and libraries
model <- glm( Arrest ~ `Primary Type` + park_dist + library_dist + art_dist, data = train.data, family = binomial)

# Make predictions
probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "TRUE", "FALSE")
# Model accuracy
cat('Logistic Regression Model Accuracy w/ added distances: ', round(mean(predicted.classes == test.data$Arrest),4) * 100, '%')
```

Summary output of the best performing model.
```{r}
# Summarize the best model
summary(model)
```

#### Results
The latitude, longitude, and type of crimes were the most statistically significant features when trying to predict the likelihood of an arrest. The distances to the nearest park and public art were also statistically significant when predicting an arrest, but the significance was slightly less. The least significant feature looked at was the distance to the nearest park, however this feature was still statistically significant. We suspect this is less significant because the libraries around Chicago are fairly evenly spread across the city. Adding the distances to the nearest park, public art, and library to the existing models using the primary type of crime and the crime location increased the models performance slightly. 


## Hypothesis 3 Testing
Days with inclement weather will have different amounts of the most common crime (Battery and Theft) than days without inclement weather

```{r}
crime_mann_whitney_test <- function(data, weather_condition) {
  weather_count <- data[weather_condition,] %>%
    group_by(date(DateTime), `Primary Type`) %>%
    count(`Primary Type`)
  
  non_weather_count <- data[!weather_condition,] %>%
    group_by(date(DateTime), `Primary Type`) %>%
    count(`Primary Type`)
  
  cat("Total number of", nrow(weather_count), "weather entries.\n")
  cat("Total number of", nrow(non_weather_count), "non-weather entries.\n")
  
  df = tibble(`Test` = c("Mann Whitney U P-Value"))
  
  for (type in unique(data$`Primary Type`)) {
    weather_occurrences <- weather_count[weather_count$`Primary Type` == type,]
    non_weather_occurrences <- non_weather_count[non_weather_count$`Primary Type` == type,]
    
    if (nrow(weather_occurrences) > 5 && nrow(non_weather_occurrences) > 5) {
      stat_result <- wilcox.test(weather_occurrences$n, non_weather_occurrences$n, exact=FALSE)
      df <- df %>% add_column(!!type := stat_result["p.value"][[1]])
    } else {
      df <- df %>% add_column(!!type := -1)
    }
  }
  
  return(df)
}
```

### Testing days with rain
```{r}
rain_p_values <- crime_mann_whitney_test(combined_data, (combined_data$PRCP > 0.0))
rain_p_values
```

These results show that some types of crimes occur statistically different amounts on days with no rain, versus rain being present. With a p-value of 0.05, we can see that the most common crimes in Chicago, `battery` and `theft` occur in different amounts on days with rain versus days without rain. This allows us to reject the null hypothesis for both battery and theft, and accept the alternate hypothesis.

### Testing days with snow
```{r}
snow_p_values <- crime_mann_whitney_test(combined_data, (combined_data$SNOW > 0.0))
snow_p_values
```

These results show that most types of crimes occur statistically different amounts on days with no snow, versus snow being present. With a p-value of 0.05, we can see that the most common crimes in Chicago, `battery` and `theft` occur significantly different amounts when there is snow, versus there not being snow. This allows us to reject the null hypothesis for both battery and theft, and accept the alternate hypothesis.

### Testing days with thunder
```{r}
thunder_p_values <- crime_mann_whitney_test(combined_data, (combined_data$Thunder == TRUE))
thunder_p_values
```

These results show that some types of crimes occur statistically different amounts on days with no thunder, versus thunder being present. With this test, we are assuming Thunder implies more severe rain than above. With a p-value of 0.05, we can see that the most common crimes in Chicago, `battery` and `theft` don't necessarily occur differently. `battery` occurs in a different quantity when thunder is present, whereas `theft` does not. This allows us to reject the null hypothesis for battery, but forces us to accept it for theft, and accept the alternate hypothesis.

### Testing a Linear Regression model

With our alternate hypothesis being accepted in most cases, we are now interested in moving to modelling. While the big difference is between there *being weather* and *not being weather*, we are curious about whether or not we can predict crime rates with the type of weather, or the amount of precipitation/snow.

```{r echo=FALSE}
grouped_data <- combined_data %>%
  group_by(date(DateTime), `Primary Type`) %>%
  count(`Primary Type`, 
        ACMH=ACMH,
        ACSH=ACSH,
        AWND=AWND,
        FMTM=FMTM,
        PGTM=PGTM, 
        PRCP=PRCP,
        PSUN=PSUN,
        SNOW=SNOW,
        SNWD=SNWD,
        TAVG=TAVG,
        TMAX=TMAX,
        TMIN=TMIN,
        TSUN=TSUN,
        WDF1=WDF1,
        WDF2=WDF2,
        WDF5=WDF5,
        WSFG=WSFG,
        WSFM=WSFM,
        Fog=Fog,
        Heavy_Fog=Heavy_Fog,
        Thunder=Thunder,
        Ice_Rain=Ice_Rain,
        Hail=Hail,
        Glaze=Glaze,
        Dust=Dust,
        Smoke=Smoke,
        Blowing_Snow=Blowing_Snow,
        Tornado=Tornado,
        High_Winds=High_Winds,
        Mist=Mist,
        Drizzle=Drizzle,
        Freezing_Drizzle=Freezing_Drizzle,
        Rain=Rain,
        Freezing_Rain=Freezing_Rain,
        Snow_Precip=Snow_Precip,
        Unknown_Precip=Unknown_Precip,
        Ground_Fog=Ground_Fog,
        Ice_Fog=Ice_Fog,
        Thunder_2=Thunder_2,
        Rain_Snow_Shower=Rain_Snow_Shower)
  
battery_data <- grouped_data[grouped_data$`Primary Type` == "BATTERY",]
battery_data <- mutate_at(battery_data, vars(-group_cols()), ~replace(., is.na(.), 0))

theft_data <- grouped_data[grouped_data$`Primary Type` == "THEFT",]
theft_data <- mutate_at(theft_data, vars(-group_cols()), ~replace(., is.na(.), 0))
```

### Testing Linear Regression Models
In the first section, we want to see if we can predict the amount of crimes per day with a linear regression between the snowfall or the precipitation versus the battery and theft crimes.

```{r}
snow_battery_model = lm(n ~ SNOW, data = battery_data)
summary(snow_battery_model)
plot(battery_data$SNOW, battery_data$n, main="Snowfall vs. Battery Crimes per Day", xlab="Snowfall (in)", ylab="Quantity of Crimes per Day")
abline(snow_battery_model)
```

```{r}
rain_battery_model = lm(n ~ PRCP, data = battery_data)
summary(rain_battery_model)
plot(battery_data$PRCP, battery_data$n, main="Rainfall vs. Battery Crimes per Day", xlab="Rainfall (in)", ylab="Quantity of Crimes per Day")
abline(rain_battery_model)
```

```{r}
snow_theft_model = lm(n ~ SNOW, data = theft_data)
summary(snow_theft_model)
plot(theft_data$SNOW, theft_data$n, main="Snowfall vs. Theft Crimes per Day", xlab="Snowfall (in)", ylab="Quantity of Crimes per Day")
abline(snow_theft_model)
```

```{r}
rain_theft_model = lm(n ~ PRCP, data = theft_data)
summary(rain_theft_model)
plot(theft_data$PRCP, theft_data$n, main="Rainfall vs. Theft Crimes per Day", xlab="Rainfall (in)", ylab="Quantity of Crimes per Day")
abline(rain_theft_model)
```
These models help illustrate that we cannot definitively predict the amount of crimes with the amount of rainfall or snowfall; the means between the two groups are different, but we cannot predict on the amount of crimes.

### Testing a Random Forests model

Next, we wanted to try to utilize more of the discrete features within the weather data to see if we can predict other features, using a random forest predictor.

#### Predicting the crimes per day based on weather

First, we wanted to try predicting the crimes per day for battery and theft based on the weather data.

```{r}
partition_idx <- createDataPartition(battery_data$n, p = 0.75, list=FALSE)
training <- battery_data[partition_idx,]
test <- battery_data[-partition_idx,]

rf <- randomForest(
  n ~ . - `date(DateTime)` - `Primary Type`,
  data=training
)

print(rf)

plot(rf, main="Battery Crimes Per Day RF Prediction Error")
```

```{r}
partition_idx <- createDataPartition(theft_data$n, p = 0.75, list=FALSE)
training <- theft_data[partition_idx,]
test <- theft_data[-partition_idx,]

rf <- randomForest(
  n ~ . - `date(DateTime)` - `Primary Type`,
  data=training
)

print(rf)

plot(rf, main="Theft Crimes Per Day RF Prediction Error")
```

These models show that while the averages of both groups are different, weather is a non-predictor of the continuous number of crimes occuring per day.

#### Predicting the average temperature per day based on weather and crimes

Next, we wanted to try to see whether or not the number of crimes could be a predictor for the average daily temperature

```{r}
partition_idx <- createDataPartition(battery_data$TAVG, p = 0.75, list=FALSE)
training <- battery_data[partition_idx,]
test <- battery_data[-partition_idx,]

rf1 <- randomForest(
  TAVG ~ . - `date(DateTime)` - `Primary Type` - n,
  data=training
)

print(rf1)

plot(rf1, main="Average Temperature Per Day without Battery Data RF Prediction Error")

rf2 <- randomForest(
  TAVG ~ . - `date(DateTime)` - `Primary Type`,
  data=training
)

print(rf2)

plot(rf2, main="Average Temperature Per Day with Battery Data RF Prediction Error")

rf3 <- randomForest(
  TAVG ~ n,
  data=training
)

print(rf3)

plot(rf3, main="Average Temperature Per Day with only Battery Data RF Prediction Error")
```

```{r}
partition_idx <- createDataPartition(theft_data$TAVG, p = 0.75, list=FALSE)
training <- theft_data[partition_idx,]
test <- theft_data[-partition_idx,]

rf1 <- randomForest(
  TAVG ~ . - `date(DateTime)` - `Primary Type` - n,
  data=training
)

print(rf1)

plot(rf1, main="Average Temperature Per Day without Theft Data RF Prediction Error")

rf2 <- randomForest(
  TAVG ~ . - `date(DateTime)` - `Primary Type`,
  data=training
)

print(rf2)

plot(rf2, main="Average Temperature Per Day with Theft Data RF Prediction Error")

rf3 <- randomForest(
  TAVG ~ n,
  data=training
)

print(rf3)

plot(rf3, main="Average Temperature Per Day with only Theft Data RF Prediction Error")
```

These models show that while the number of crimes can have a slight improvement to the prediction of the daily average temperature, it is nearly insignificant in most cases.

#### Predicting the presence of fog on a day based on weather and crimes

Finally, we wanted to predict the presence of Fog (general weather feature likely in most inclement weather) based on the crimes per day.

```{r}
battery_data$Fog <- as.factor(battery_data$Fog)

partition_idx <- createDataPartition(battery_data$Fog, p = 0.75, list=FALSE)
training <- battery_data[partition_idx,]
test <- battery_data[-partition_idx,]

rf <- randomForest(
  Fog ~ n,
  data=training
)

print(rf)

plot(rf, main="Presence of Fog with Battery Data RF Prediction Error")
```

```{r}
theft_data$Fog <- as.factor(theft_data$Fog)

partition_idx <- createDataPartition(theft_data$Fog, p = 0.75, list=FALSE)
training <- theft_data[partition_idx,]
test <- theft_data[-partition_idx,]

rf <- randomForest(
  Fog ~ n,
  data=training
)

print(rf)

plot(rf, main="Presence of Fog with Theft Data RF Prediction Error")
```
This data shows that we cannot definitively predict whether or not there is fog based on the number of crimes per day. While we are able to get some values, this is likely due to random chance.


### Recap
We were able to prove and accept our alternative hypothesis that the weather impacts the number of crimes per day for most crimes in Chicago. When looking to predict the number of crimes per day, and the weather of a given day, our models performed very poorly and failed to predict in most cases. This could likely be improved with other data, but when directly analyzing the correlation between weather and crimes, there is little relationship when looking at continuous variables.

## Results Analysis
1) Hypothesis 1 was rejected.  We rejected our alternative hypothesis that the likelihood of an arrest occurring for a crime using the crime type and weather data could not be accurately predicted. However, the crime type and some of the weather features such as percipitation, snow, and temperature were statistically significant compared to an arrest occurring. The significance was not enough to contribute to the predictions of a model.



2) Hypothesis 2 was accepted. We were able to prove and accept our alternative hypothesis that the likelihood of an arrest occurring for a crime was impacted by the crime type and the crime's location in relation to parks, public art, and libraries. Our best model was able to predict arrest likelihood with a 90.3% accuracy. The crime type, crime location, and crimes distance to the nearest park, public art, and library were all statistically significant compared to an arrest occurring.



3) Hypothesis 3 was accepted. We were able to prove and accept our alternative hypothesis that the weather impacts the number of crimes per day for most crimes in Chicago. When looking to predict the number of crimes per day, and the weather of a given day, our models performed very poorly and failed to predict in most cases. This could likely be improved with other data, but when directly analyzing the correlation between weather and crimes, there is little relationship when looking at continuous variables.

We learned a lot about evaluating hypotheses during this project. Specifically, we had a few ideas of what to look for, but didn't know what to expect. Through our analysis, we found that some of our hypotheses didn't translate to models - making it impossible to generate predictions in some cases. We were able to learn a lot about testing different hypotheses, and working off of what was evaluated. For example, working on hypothesis 3, we figured out that we weren't able to model on the data, however, we were able to derive additional tests (such as looking at the predictive capability of different features) to determine the composition and layout of the data. 

We also were able to learn a lot about R through this assignment. Focusing more on statistical testing in R would have made different areas of this project much easier, but we all feel that we were able to pick up on the assignment relatively fast.
